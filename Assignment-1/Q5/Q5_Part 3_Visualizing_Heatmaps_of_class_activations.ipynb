{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as k\n",
    "from keras.preprocessing import image\n",
    "#from keras.applications.vgg16 import preprocessing_input, decode_predictions\n",
    "import numpy as np\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 16)        104       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               410112    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 96)                49248     \n",
      "=================================================================\n",
      "Total params: 464,552\n",
      "Trainable params: 464,500\n",
      "Non-trainable params: 52\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "model = tf.keras.models.load_model('/home/gitanjali/Desktop/Deep_learning/DL_2020/assignment1/Q3_PART2_Line_dataset_variation2_saveas_with_architecture.h5')\n",
    "model.summary()  # As a reminder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/gitanjali/Desktop/Deep_learning/DL_2020/assignment1/line_data/Class20/1_1_4_0_0.jpg\"\n",
    "img = image.load_img(img_path, target_size=(28,28))\n",
    "x = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add a dimension to transfer our array into a \"batch\"\n",
    "# of size (1, 224,224,3)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "# final we preprocess the batch\n",
    "# (this does channel-wise color normalization)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run pretrained network on the target image and decode its prediction vector back\n",
    "preds = model.predict(x)\n",
    "print('predicted:', preds)\n",
    "np.argmax(preds[0])\n",
    "#print(np.argmax[preds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize which part of input/target image are the most hand_made or computer made art\n",
    "# the convolutional layer\n",
    "\n",
    "art_output = model.output[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the output feature map of the 'block5pool' layer,\n",
    "# last output feature map of 'block5_pool'\n",
    "\n",
    "last_conv_layer = model.get_layer('conv2d_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gradients/max_pooling2d_1/MaxPool_grad/MaxPoolGrad:0\", shape=(None, 11, 11, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# this is the gradient of the \"hand_made/computer_made\" class with regards to\n",
    "#the output feature map of 'block5pool'\n",
    "grads = k.gradients(art_output, last_conv_layer.output)[0]\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(32,), dtype=float32)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# this is a vector of shape (512,), where each entry\n",
    "# is the mean intensity of the graident over a specific features map channel\n",
    "pooled_grads = k.mean(grads, axis=(0, 1, 2))\n",
    "print(pooled_grads)\n",
    "print(pooled_grads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function allows us to access the value of the quantities we just defined:\n",
    "# 'pooled_grads' and the output feature map of 'block5_conv3'.\n",
    "#given a sample image\n",
    "iterate = k.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 32)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "# these are the values of these two quantities, as numpy array,\n",
    "# given our sample image\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "print(conv_layer_output_value.shape) # 7,7,512\n",
    "print(pooled_grads_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we multiply the each channel in the feature map array\n",
    "# by \"how important this channel is\" with regards to the image class\n",
    "# don't know why but it does not work with 512 number as they are the total number of filters for the layer\n",
    "for i in range(31):\n",
    "\tconv_layer_output_value[:, :, i] *=pooled_grads_value[i]\n",
    "# the channel-wise mean of the resulting feature map\n",
    "# is our heatmap of class activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "#print(heatmap)\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "#we use cv2 to load the original image\n",
    "img = cv2.imread(img_path)\n",
    "# we resize the heatmap to have the same size as the original image\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "#we convert the heatmap to RGB\n",
    "heatmap = np.uint8(255*heatmap)\n",
    "# we apply the heatmap to the original image\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "#0.4 here is a heatmap intensity factor\n",
    "superimposed_img = heatmap * 1.2 +img\n",
    "#save the image to disk\n",
    "cv2.imwrite('/home/gitanjali/Desktop/feature_map.jpg', superimposed_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"output\",superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
